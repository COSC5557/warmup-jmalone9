import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

#this bit was mostly from the pandas dataframe and csv reading documentation
wine = pd.read_csv('winequality-red.csv', sep=';', header = 'infer')
#wine.sort_values(by = wine.columns[11])
y = wine.iloc[:,11]
x = wine.drop(wine.columns[11], axis = 1)

#code inspired from https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py 
#and https://realpython.com/linear-regression-in-python/

#for i in range(20): #this loop was to get a bunch of outputs
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2) #changing the test size doesnt seem to impact results much


#create linear regression objext
regr = linear_model.LinearRegression()
#train the model
regr.fit(x_train, y_train)
#make predictions
y_pred = regr.predict(x_test)

#print mean squared error and r2 score
print("Mean Squared Error:", mean_squared_error(y_test, y_pred)) #between 0.35 and 0.52
print("Coefficient of determination:", r2_score(y_test, y_pred)) #between 0.28 and 0.48


#this block here lets me graph the 'line' generated by attribute, though it's a bit messy looking
plt.figure(figsize=(10,10))

#can change this to any attribute to graph the relationship between it and the quality, alcohol seems to be a pretty steep line, and same with volatile acidity in the other direction
xtemp = x_test['alcohol'].squeeze() #found out how to do this from https://datatofish.com/pandas-dataframe-to-series/
plt.scatter(xtemp, y_test, color="black")
plt.plot(xtemp, y_pred, color="blue", linewidth=3)
plt.show()